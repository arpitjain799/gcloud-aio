<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>gcloud.aio.bigquery API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gcloud.aio.bigquery</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from pkg_resources import get_distribution
__version__ = get_distribution(&#39;gcloud-aio-bigquery&#39;).version

from gcloud.aio.bigquery.bigquery import Disposition
from gcloud.aio.bigquery.bigquery import SCOPES
from gcloud.aio.bigquery.bigquery import SchemaUpdateOption
from gcloud.aio.bigquery.bigquery import SourceFormat
from gcloud.aio.bigquery.dataset import Dataset
from gcloud.aio.bigquery.job import Job
from gcloud.aio.bigquery.table import Table
from gcloud.aio.bigquery.utils import query_response_to_dict


__all__ = [
    &#39;__version__&#39;,
    &#39;Dataset&#39;,
    &#39;Disposition&#39;,
    &#39;Job&#39;,
    &#39;SCOPES&#39;,
    &#39;SchemaUpdateOption&#39;,
    &#39;SourceFormat&#39;,
    &#39;Table&#39;,
    &#39;query_response_to_dict&#39;,
]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="gcloud.aio.bigquery.bigquery" href="bigquery.html">gcloud.aio.bigquery.bigquery</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="gcloud.aio.bigquery.dataset" href="dataset.html">gcloud.aio.bigquery.dataset</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="gcloud.aio.bigquery.job" href="job.html">gcloud.aio.bigquery.job</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="gcloud.aio.bigquery.table" href="table.html">gcloud.aio.bigquery.table</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="gcloud.aio.bigquery.utils" href="utils.html">gcloud.aio.bigquery.utils</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="gcloud.aio.bigquery.query_response_to_dict"><code class="name flex">
<span>def <span class="ident">query_response_to_dict</span></span>(<span>response: Dict[str, Any]) ‑> List[Dict[str, Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a query response to a dictionary.</p>
<p>API responses for job queries are packed into a difficult-to-use format.
This method deserializes a response into a List of rows, with each row
being a dictionary of field names to the row's value.</p>
<p>This method also handles converting the values according to the schema
defined in the response (eg. into builtin python types).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def query_response_to_dict(response: Dict[str, Any]) -&gt; List[Dict[str, Any]]:
    &#34;&#34;&#34;
    Convert a query response to a dictionary.

    API responses for job queries are packed into a difficult-to-use format.
    This method deserializes a response into a List of rows, with each row
    being a dictionary of field names to the row&#39;s value.

    This method also handles converting the values according to the schema
    defined in the response (eg. into builtin python types).
    &#34;&#34;&#34;
    fields = response[&#39;schema&#39;].get(&#39;fields&#39;, [])
    rows = [x[&#39;f&#39;] for x in response.get(&#39;rows&#39;, [])]
    return [{k[&#39;name&#39;]: parse(k, v) for k, v in zip(fields, row)}
            for row in rows]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="gcloud.aio.bigquery.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>dataset_name: Optional[str] = None, project: Optional[str] = None, service_file: Union[str, IO[~AnyStr], ForwardRef(None)] = None, session: Optional[aiohttp.client.ClientSession] = None, token: Optional[<a title="gcloud.aio.auth.token.Token" href="../auth/token.html#gcloud.aio.auth.token.Token">Token</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataset(BigqueryBase):
    def __init__(self, dataset_name: Optional[str] = None,
                 project: Optional[str] = None,
                 service_file: Optional[Union[str, IO[AnyStr]]] = None,
                 session: Optional[Session] = None,
                 token: Optional[Token] = None) -&gt; None:
        self.dataset_name = dataset_name
        super().__init__(project=project, service_file=service_file,
                         session=session, token=token)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/list
    async def list_tables(
            self, session: Optional[Session] = None,
            timeout: int = 60,
            params: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;List tables in a dataset.&#34;&#34;&#34;
        project = await self.project()
        if not self.dataset_name:
            raise ValueError(&#39;could not determine dataset,&#39;
                             &#39; please set it manually&#39;)

        url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
               f&#39;{self.dataset_name}/tables&#39;)
        return await self._get_url(url, session, timeout, params=params)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list
    async def list_datasets(
            self, session: Optional[Session] = None,
            timeout: int = 60,
            params: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;List datasets in current project.&#34;&#34;&#34;
        project = await self.project()

        url = (f&#39;{API_ROOT}/projects/{project}/datasets&#39;)
        return await self._get_url(url, session, timeout, params=params)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/get
    async def get(self, session: Optional[Session] = None,
                  timeout: int = 60,
                  params: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Get a specific dataset in current project.&#34;&#34;&#34;
        project = await self.project()
        if not self.dataset_name:
            raise ValueError(&#39;could not determine dataset,&#39;
                             &#39; please set it manually&#39;)

        url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
               f&#39;{self.dataset_name}&#39;)
        return await self._get_url(url, session, timeout, params=params)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert
    async def insert(self, dataset: Dict[str, Any],
                     session: Optional[Session] = None,
                     timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Create datasets in current project.&#34;&#34;&#34;
        project = await self.project()

        url = (f&#39;{API_ROOT}/projects/{project}/datasets&#39;)
        return await self._post_json(url, dataset, session, timeout)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="gcloud.aio.bigquery.bigquery.BigqueryBase" href="bigquery.html#gcloud.aio.bigquery.bigquery.BigqueryBase">BigqueryBase</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="gcloud.aio.bigquery.Dataset.get"><code class="name flex">
<span>async def <span class="ident">get</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60, params: Optional[Dict[str, Any]] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Get a specific dataset in current project.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def get(self, session: Optional[Session] = None,
              timeout: int = 60,
              params: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Get a specific dataset in current project.&#34;&#34;&#34;
    project = await self.project()
    if not self.dataset_name:
        raise ValueError(&#39;could not determine dataset,&#39;
                         &#39; please set it manually&#39;)

    url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
           f&#39;{self.dataset_name}&#39;)
    return await self._get_url(url, session, timeout, params=params)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Dataset.insert"><code class="name flex">
<span>async def <span class="ident">insert</span></span>(<span>self, dataset: Dict[str, Any], session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Create datasets in current project.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert(self, dataset: Dict[str, Any],
                 session: Optional[Session] = None,
                 timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Create datasets in current project.&#34;&#34;&#34;
    project = await self.project()

    url = (f&#39;{API_ROOT}/projects/{project}/datasets&#39;)
    return await self._post_json(url, dataset, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Dataset.list_datasets"><code class="name flex">
<span>async def <span class="ident">list_datasets</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60, params: Optional[Dict[str, Any]] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>List datasets in current project.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def list_datasets(
        self, session: Optional[Session] = None,
        timeout: int = 60,
        params: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;List datasets in current project.&#34;&#34;&#34;
    project = await self.project()

    url = (f&#39;{API_ROOT}/projects/{project}/datasets&#39;)
    return await self._get_url(url, session, timeout, params=params)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Dataset.list_tables"><code class="name flex">
<span>async def <span class="ident">list_tables</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60, params: Optional[Dict[str, Any]] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>List tables in a dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def list_tables(
        self, session: Optional[Session] = None,
        timeout: int = 60,
        params: Optional[Dict[str, Any]] = None) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;List tables in a dataset.&#34;&#34;&#34;
    project = await self.project()
    if not self.dataset_name:
        raise ValueError(&#39;could not determine dataset,&#39;
                         &#39; please set it manually&#39;)

    url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
           f&#39;{self.dataset_name}/tables&#39;)
    return await self._get_url(url, session, timeout, params=params)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="gcloud.aio.bigquery.Disposition"><code class="flex name class">
<span>class <span class="ident">Disposition</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>An enumeration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Disposition(Enum):
    WRITE_APPEND = &#39;WRITE_APPEND&#39;
    WRITE_EMPTY = &#39;WRITE_EMPTY&#39;
    WRITE_TRUNCATE = &#39;WRITE_TRUNCATE&#39;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="gcloud.aio.bigquery.Disposition.WRITE_APPEND"><code class="name">var <span class="ident">WRITE_APPEND</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.Disposition.WRITE_EMPTY"><code class="name">var <span class="ident">WRITE_EMPTY</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.Disposition.WRITE_TRUNCATE"><code class="name">var <span class="ident">WRITE_TRUNCATE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="gcloud.aio.bigquery.Job"><code class="flex name class">
<span>class <span class="ident">Job</span></span>
<span>(</span><span>job_id: Optional[str] = None, project: Optional[str] = None, service_file: Union[str, IO[~AnyStr], ForwardRef(None)] = None, session: Optional[aiohttp.client.ClientSession] = None, token: Optional[<a title="gcloud.aio.auth.token.Token" href="../auth/token.html#gcloud.aio.auth.token.Token">Token</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Job(BigqueryBase):
    def __init__(self, job_id: Optional[str] = None,
                 project: Optional[str] = None,
                 service_file: Optional[Union[str, IO[AnyStr]]] = None,
                 session: Optional[Session] = None,
                 token: Optional[Token] = None) -&gt; None:
        self.job_id = job_id
        super().__init__(project=project, service_file=service_file,
                         session=session, token=token)

    @staticmethod
    def _make_query_body(
            query: str,
            write_disposition: Disposition,
            use_query_cache: bool,
            dry_run: bool, use_legacy_sql: bool,
            destination_table: Optional[Any]) -&gt; Dict[str, Any]:
        return {
            &#39;configuration&#39;: {
                &#39;query&#39;: {
                    &#39;query&#39;: query,
                    &#39;writeDisposition&#39;: write_disposition.value,
                    &#39;destinationTable&#39;: {
                        &#39;projectId&#39;: destination_table.project,
                        &#39;datasetId&#39;: destination_table.dataset_name,
                        &#39;tableId&#39;: destination_table.table_name,
                    } if destination_table else destination_table,
                    &#39;useQueryCache&#39;: use_query_cache,
                    &#39;useLegacySql&#39;: use_legacy_sql,
                },
                &#39;dryRun&#39;: dry_run,
            },
        }

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get
    async def get_job(self, session: Optional[Session] = None,
                      timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Get the specified job resource by job ID.&#34;&#34;&#34;

        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/jobs/{self.job_id}&#39;

        return await self._get_url(url, session, timeout)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/getQueryResults
    async def get_query_results(self, session: Optional[Session] = None,
                                timeout: int = 60,
                                params: Optional[Dict[str, Any]] = None,
                                ) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Get the specified jobQueryResults by job ID.&#34;&#34;&#34;

        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/queries/{self.job_id}&#39;

        return await self._get_url(url, session, timeout, params=params)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel
    async def cancel(self, session: Optional[Session] = None,
                     timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Cancel the specified job by job ID.&#34;&#34;&#34;

        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/queries/{self.job_id}/cancel&#39;

        return await self._post_json(url, {}, session, timeout)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query
    async def query(self, query_request: Dict[str, Any],
                    session: Optional[Session] = None,
                    timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Runs a query synchronously and returns query results if completes
        within a specified timeout.&#34;&#34;&#34;
        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/queries&#39;

        return await self._post_json(url, query_request, session, timeout)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert
    async def insert(self, job: Dict[str, Any],
                     session: Optional[Session] = None,
                     timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Insert a new asynchronous job.&#34;&#34;&#34;
        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

        response = await self._post_json(url, job, session, timeout)
        if response[&#39;jobReference&#39;].get(&#39;jobId&#39;):
            self.job_id = response[&#39;jobReference&#39;][&#39;jobId&#39;]
        return response

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert
    # https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery
    async def insert_via_query(
            self, query: str, session: Optional[Session] = None,
            write_disposition: Disposition = Disposition.WRITE_EMPTY,
            timeout: int = 60, use_query_cache: bool = True,
            dry_run: bool = False, use_legacy_sql: bool = True,
            destination_table: Optional[Any] = None) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Create table as a result of the query&#34;&#34;&#34;
        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

        body = self._make_query_body(query=query,
                                     write_disposition=write_disposition,
                                     use_query_cache=use_query_cache,
                                     dry_run=dry_run,
                                     use_legacy_sql=use_legacy_sql,
                                     destination_table=destination_table)
        response = await self._post_json(url, body, session, timeout)
        if not dry_run:
            self.job_id = response[&#39;jobReference&#39;][&#39;jobId&#39;]
        return response

    async def result(self,
                     session: Optional[Session] = None) -&gt; Dict[str, Any]:
        data = await self.get_job(session)
        status = data.get(&#39;status&#39;, {})
        if status.get(&#39;state&#39;) == &#39;DONE&#39;:
            if &#39;errorResult&#39; in status:
                raise Exception(&#39;Job finished with errors&#39;, status[&#39;errors&#39;])
            return data

        raise OSError(&#39;Job results are still pending&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="gcloud.aio.bigquery.bigquery.BigqueryBase" href="bigquery.html#gcloud.aio.bigquery.bigquery.BigqueryBase">BigqueryBase</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="gcloud.aio.bigquery.Job.cancel"><code class="name flex">
<span>async def <span class="ident">cancel</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Cancel the specified job by job ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def cancel(self, session: Optional[Session] = None,
                 timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Cancel the specified job by job ID.&#34;&#34;&#34;

    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/queries/{self.job_id}/cancel&#39;

    return await self._post_json(url, {}, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Job.get_job"><code class="name flex">
<span>async def <span class="ident">get_job</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the specified job resource by job ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def get_job(self, session: Optional[Session] = None,
                  timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Get the specified job resource by job ID.&#34;&#34;&#34;

    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/jobs/{self.job_id}&#39;

    return await self._get_url(url, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Job.get_query_results"><code class="name flex">
<span>async def <span class="ident">get_query_results</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60, params: Optional[Dict[str, Any]] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the specified jobQueryResults by job ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def get_query_results(self, session: Optional[Session] = None,
                            timeout: int = 60,
                            params: Optional[Dict[str, Any]] = None,
                            ) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Get the specified jobQueryResults by job ID.&#34;&#34;&#34;

    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/queries/{self.job_id}&#39;

    return await self._get_url(url, session, timeout, params=params)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Job.insert"><code class="name flex">
<span>async def <span class="ident">insert</span></span>(<span>self, job: Dict[str, Any], session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Insert a new asynchronous job.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert(self, job: Dict[str, Any],
                 session: Optional[Session] = None,
                 timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Insert a new asynchronous job.&#34;&#34;&#34;
    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

    response = await self._post_json(url, job, session, timeout)
    if response[&#39;jobReference&#39;].get(&#39;jobId&#39;):
        self.job_id = response[&#39;jobReference&#39;][&#39;jobId&#39;]
    return response</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Job.insert_via_query"><code class="name flex">
<span>async def <span class="ident">insert_via_query</span></span>(<span>self, query: str, session: Optional[aiohttp.client.ClientSession] = None, write_disposition: <a title="gcloud.aio.bigquery.bigquery.Disposition" href="bigquery.html#gcloud.aio.bigquery.bigquery.Disposition">Disposition</a> = Disposition.WRITE_EMPTY, timeout: int = 60, use_query_cache: bool = True, dry_run: bool = False, use_legacy_sql: bool = True, destination_table: Optional[Any] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Create table as a result of the query</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert_via_query(
        self, query: str, session: Optional[Session] = None,
        write_disposition: Disposition = Disposition.WRITE_EMPTY,
        timeout: int = 60, use_query_cache: bool = True,
        dry_run: bool = False, use_legacy_sql: bool = True,
        destination_table: Optional[Any] = None) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Create table as a result of the query&#34;&#34;&#34;
    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

    body = self._make_query_body(query=query,
                                 write_disposition=write_disposition,
                                 use_query_cache=use_query_cache,
                                 dry_run=dry_run,
                                 use_legacy_sql=use_legacy_sql,
                                 destination_table=destination_table)
    response = await self._post_json(url, body, session, timeout)
    if not dry_run:
        self.job_id = response[&#39;jobReference&#39;][&#39;jobId&#39;]
    return response</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Job.query"><code class="name flex">
<span>async def <span class="ident">query</span></span>(<span>self, query_request: Dict[str, Any], session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Runs a query synchronously and returns query results if completes
within a specified timeout.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def query(self, query_request: Dict[str, Any],
                session: Optional[Session] = None,
                timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Runs a query synchronously and returns query results if completes
    within a specified timeout.&#34;&#34;&#34;
    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/queries&#39;

    return await self._post_json(url, query_request, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Job.result"><code class="name flex">
<span>async def <span class="ident">result</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def result(self,
                 session: Optional[Session] = None) -&gt; Dict[str, Any]:
    data = await self.get_job(session)
    status = data.get(&#39;status&#39;, {})
    if status.get(&#39;state&#39;) == &#39;DONE&#39;:
        if &#39;errorResult&#39; in status:
            raise Exception(&#39;Job finished with errors&#39;, status[&#39;errors&#39;])
        return data

    raise OSError(&#39;Job results are still pending&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="gcloud.aio.bigquery.SchemaUpdateOption"><code class="flex name class">
<span>class <span class="ident">SchemaUpdateOption</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>An enumeration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SchemaUpdateOption(Enum):
    ALLOW_FIELD_ADDITION = &#39;ALLOW_FIELD_ADDITION&#39;
    ALLOW_FIELD_RELAXATION = &#39;ALLOW_FIELD_RELAXATION&#39;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="gcloud.aio.bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION"><code class="name">var <span class="ident">ALLOW_FIELD_ADDITION</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.SchemaUpdateOption.ALLOW_FIELD_RELAXATION"><code class="name">var <span class="ident">ALLOW_FIELD_RELAXATION</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="gcloud.aio.bigquery.SourceFormat"><code class="flex name class">
<span>class <span class="ident">SourceFormat</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>An enumeration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SourceFormat(Enum):
    AVRO = &#39;AVRO&#39;
    CSV = &#39;CSV&#39;
    DATASTORE_BACKUP = &#39;DATASTORE_BACKUP&#39;
    NEWLINE_DELIMITED_JSON = &#39;NEWLINE_DELIMITED_JSON&#39;
    ORC = &#39;ORC&#39;
    PARQUET = &#39;PARQUET&#39;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="gcloud.aio.bigquery.SourceFormat.AVRO"><code class="name">var <span class="ident">AVRO</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.SourceFormat.CSV"><code class="name">var <span class="ident">CSV</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.SourceFormat.DATASTORE_BACKUP"><code class="name">var <span class="ident">DATASTORE_BACKUP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.SourceFormat.NEWLINE_DELIMITED_JSON"><code class="name">var <span class="ident">NEWLINE_DELIMITED_JSON</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.SourceFormat.ORC"><code class="name">var <span class="ident">ORC</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="gcloud.aio.bigquery.SourceFormat.PARQUET"><code class="name">var <span class="ident">PARQUET</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="gcloud.aio.bigquery.Table"><code class="flex name class">
<span>class <span class="ident">Table</span></span>
<span>(</span><span>dataset_name: str, table_name: str, project: Optional[str] = None, service_file: Union[str, IO[~AnyStr], ForwardRef(None)] = None, session: Optional[aiohttp.client.ClientSession] = None, token: Optional[<a title="gcloud.aio.auth.token.Token" href="../auth/token.html#gcloud.aio.auth.token.Token">Token</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Table(BigqueryBase):
    def __init__(self, dataset_name: str, table_name: str,
                 project: Optional[str] = None,
                 service_file: Optional[Union[str, IO[AnyStr]]] = None,
                 session: Optional[Session] = None,
                 token: Optional[Token] = None) -&gt; None:
        self.dataset_name = dataset_name
        self.table_name = table_name
        super().__init__(project=project, service_file=service_file,
                         session=session, token=token)

    @staticmethod
    def _mk_unique_insert_id(row: Dict[str, Any]) -&gt; str:
        # pylint: disable=unused-argument
        return uuid.uuid4().hex

    def _make_copy_body(
            self, source_project: str, destination_project: str,
            destination_dataset: str,
            destination_table: str) -&gt; Dict[str, Any]:
        return {
            &#39;configuration&#39;: {
                &#39;copy&#39;: {
                    &#39;writeDisposition&#39;: &#39;WRITE_TRUNCATE&#39;,
                    &#39;destinationTable&#39;: {
                        &#39;projectId&#39;: destination_project,
                        &#39;datasetId&#39;: destination_dataset,
                        &#39;tableId&#39;: destination_table,
                    },
                    &#39;sourceTable&#39;: {
                        &#39;projectId&#39;: source_project,
                        &#39;datasetId&#39;: self.dataset_name,
                        &#39;tableId&#39;: self.table_name,
                    }
                }
            }
        }

    @staticmethod
    def _make_insert_body(
            rows: List[Dict[str, Any]], *, skip_invalid: bool,
            ignore_unknown: bool, template_suffix: Optional[str],
            insert_id_fn: Callable[[Dict[str, Any]], str]) -&gt; Dict[str, Any]:
        body = {
            &#39;kind&#39;: &#39;bigquery#tableDataInsertAllRequest&#39;,
            &#39;skipInvalidRows&#39;: skip_invalid,
            &#39;ignoreUnknownValues&#39;: ignore_unknown,
            &#39;rows&#39;: [{
                &#39;insertId&#39;: insert_id_fn(row),
                &#39;json&#39;: row,
            } for row in rows],
        }

        if template_suffix is not None:
            body[&#39;templateSuffix&#39;] = template_suffix

        return body

    def _make_load_body(
            self, source_uris: List[str], project: str, autodetect: bool,
            source_format: SourceFormat,
            write_disposition: Disposition,
            ignore_unknown_values: bool,
            schema_update_options: List[SchemaUpdateOption]
    ) -&gt; Dict[str, Any]:
        return {
            &#39;configuration&#39;: {
                &#39;load&#39;: {
                    &#39;autodetect&#39;: autodetect,
                    &#39;ignoreUnknownValues&#39;: ignore_unknown_values,
                    &#39;sourceUris&#39;: source_uris,
                    &#39;sourceFormat&#39;: source_format.value,
                    &#39;writeDisposition&#39;: write_disposition.value,
                    &#39;schemaUpdateOptions&#39;: [
                        e.value for e in schema_update_options],
                    &#39;destinationTable&#39;: {
                        &#39;projectId&#39;: project,
                        &#39;datasetId&#39;: self.dataset_name,
                        &#39;tableId&#39;: self.table_name,
                    },
                },
            },
        }

    def _make_query_body(
            self, query: str, project: str,
            write_disposition: Disposition,
            use_query_cache: bool,
            dry_run: bool) -&gt; Dict[str, Any]:
        return {
            &#39;configuration&#39;: {
                &#39;query&#39;: {
                    &#39;query&#39;: query,
                    &#39;writeDisposition&#39;: write_disposition.value,
                    &#39;destinationTable&#39;: {
                        &#39;projectId&#39;: project,
                        &#39;datasetId&#39;: self.dataset_name,
                        &#39;tableId&#39;: self.table_name,
                    },
                    &#39;useQueryCache&#39;: use_query_cache,
                },
                &#39;dryRun&#39;: dry_run,
            },
        }

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert
    async def create(self, table: Dict[str, Any],
                     session: Optional[Session] = None,
                     timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Create the table specified by tableId from the dataset.&#34;&#34;&#34;
        project = await self.project()
        url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
               f&#39;{self.dataset_name}/tables&#39;)

        table[&#39;tableReference&#39;] = {
            &#39;projectId&#39;: project,
            &#39;datasetId&#39;: self.dataset_name,
            &#39;tableId&#39;: self.table_name
        }

        return await self._post_json(url, table, session, timeout)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/patch
    async def patch(self, table: Dict[str, Any],
                    session: Optional[Session] = None,
                    timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Patch an existing table specified by tableId from the dataset.&#34;&#34;&#34;
        project = await self.project()
        url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
               f&#39;{self.dataset_name}/tables/{self.table_name}&#39;)

        table[&#39;tableReference&#39;] = {
            &#39;projectId&#39;: project,
            &#39;datasetId&#39;: self.dataset_name,
            &#39;tableId&#39;: self.table_name
        }
        table_data = json.dumps(table).encode(&#39;utf-8&#39;)

        headers = await self.headers()

        s = AioSession(session) if session else self.session
        # TODO: the type issue will be fixed in auth-4.0.2
        resp = await s.patch(url, data=table_data,  # type: ignore[arg-type]
                             headers=headers, timeout=timeout)
        data: Dict[str, Any] = await resp.json()
        return data

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/delete
    async def delete(self,
                     session: Optional[Session] = None,
                     timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Deletes the table specified by tableId from the dataset.&#34;&#34;&#34;
        project = await self.project()
        url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
               f&#39;{self.dataset_name}/tables/{self.table_name}&#39;)

        headers = await self.headers()

        s = AioSession(session) if session else self.session
        resp = await s.session.delete(url, headers=headers, params=None,
                                      timeout=timeout)
        try:
            data: Dict[str, Any] = await resp.json()
        except Exception:  # pylint: disable=broad-except
            # For some reason, `gcloud-rest` seems to have intermittent issues
            # parsing this response. In that case, fall back to returning the
            # raw response body.
            try:
                data = {&#39;response&#39;: await resp.text()}
            except (AttributeError, TypeError):
                data = {&#39;response&#39;: resp.text}

        return data

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/get
    async def get(
            self, session: Optional[Session] = None,
            timeout: int = 60) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;Gets the specified table resource by table ID.&#34;&#34;&#34;
        project = await self.project()
        url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
               f&#39;{self.dataset_name}/tables/{self.table_name}&#39;)

        return await self._get_url(url, session, timeout)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/insertAll
    async def insert(
            self, rows: List[Dict[str, Any]], skip_invalid: bool = False,
            ignore_unknown: bool = True, session: Optional[Session] = None,
            template_suffix: Optional[str] = None,
            timeout: int = 60, *,
            insert_id_fn: Optional[Callable[[Dict[str, Any]], str]] = None,
    ) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Streams data into BigQuery

        By default, each row is assigned a unique insertId. This can be
        customized by supplying an `insert_id_fn` which takes a row and
        returns an insertId.

        In cases where at least one row has successfully been inserted and at
        least one row has failed to be inserted, the Google API will return a
        2xx (successful) response along with an `insertErrors` key in the
        response JSON containing details on the failing rows.
        &#34;&#34;&#34;
        if not rows:
            return {}

        project = await self.project()
        url = (f&#39;{API_ROOT}/projects/{project}/datasets/{self.dataset_name}/&#39;
               f&#39;tables/{self.table_name}/insertAll&#39;)

        body = self._make_insert_body(
            rows, skip_invalid=skip_invalid, ignore_unknown=ignore_unknown,
            template_suffix=template_suffix,
            insert_id_fn=insert_id_fn or self._mk_unique_insert_id)
        return await self._post_json(url, body, session, timeout)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert
    # https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#jobconfigurationtablecopy
    async def insert_via_copy(
            self, destination_project: str, destination_dataset: str,
            destination_table: str, session: Optional[Session] = None,
            timeout: int = 60) -&gt; Job:
        &#34;&#34;&#34;Copy BQ table to another table in BQ&#34;&#34;&#34;
        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

        body = self._make_copy_body(
            project, destination_project,
            destination_dataset, destination_table)
        response = await self._post_json(url, body, session, timeout)
        return Job(response[&#39;jobReference&#39;][&#39;jobId&#39;], self._project,
                   session=self.session.session,  # type: ignore[arg-type]
                   token=self.token)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert
    # https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad
    async def insert_via_load(
            self, source_uris: List[str], session: Optional[Session] = None,
            autodetect: bool = False,
            source_format: SourceFormat = SourceFormat.CSV,
            write_disposition: Disposition = Disposition.WRITE_TRUNCATE,
            timeout: int = 60,
            ignore_unknown_values: bool = False,
            schema_update_options: Optional[List[SchemaUpdateOption]] = None
    ) -&gt; Job:
        &#34;&#34;&#34;Loads entities from storage to BigQuery.&#34;&#34;&#34;
        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

        body = self._make_load_body(
            source_uris, project, autodetect, source_format, write_disposition,
            ignore_unknown_values, schema_update_options or []
        )
        response = await self._post_json(url, body, session, timeout)
        return Job(response[&#39;jobReference&#39;][&#39;jobId&#39;], self._project,
                   session=self.session.session,  # type: ignore[arg-type]
                   token=self.token)

    # https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/insert
    # https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery
    async def insert_via_query(
            self, query: str, session: Optional[Session] = None,
            write_disposition: Disposition = Disposition.WRITE_EMPTY,
            timeout: int = 60, use_query_cache: bool = True,
            dry_run: bool = False) -&gt; Job:
        &#34;&#34;&#34;Create table as a result of the query&#34;&#34;&#34;
        warnings.warn(&#39;using Table#insert_via_query is deprecated.&#39;
                      &#39;use Job#insert_via_query instead&#39;, DeprecationWarning)
        project = await self.project()
        url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

        body = self._make_query_body(query, project, write_disposition,
                                     use_query_cache, dry_run)
        response = await self._post_json(url, body, session, timeout)
        job_id = response[&#39;jobReference&#39;][&#39;jobId&#39;] if not dry_run else None
        return Job(job_id, self._project, token=self.token,
                   session=self.session.session)  # type: ignore[arg-type]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="gcloud.aio.bigquery.bigquery.BigqueryBase" href="bigquery.html#gcloud.aio.bigquery.bigquery.BigqueryBase">BigqueryBase</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="gcloud.aio.bigquery.Table.create"><code class="name flex">
<span>async def <span class="ident">create</span></span>(<span>self, table: Dict[str, Any], session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Create the table specified by tableId from the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def create(self, table: Dict[str, Any],
                 session: Optional[Session] = None,
                 timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Create the table specified by tableId from the dataset.&#34;&#34;&#34;
    project = await self.project()
    url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
           f&#39;{self.dataset_name}/tables&#39;)

    table[&#39;tableReference&#39;] = {
        &#39;projectId&#39;: project,
        &#39;datasetId&#39;: self.dataset_name,
        &#39;tableId&#39;: self.table_name
    }

    return await self._post_json(url, table, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.delete"><code class="name flex">
<span>async def <span class="ident">delete</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Deletes the table specified by tableId from the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def delete(self,
                 session: Optional[Session] = None,
                 timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Deletes the table specified by tableId from the dataset.&#34;&#34;&#34;
    project = await self.project()
    url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
           f&#39;{self.dataset_name}/tables/{self.table_name}&#39;)

    headers = await self.headers()

    s = AioSession(session) if session else self.session
    resp = await s.session.delete(url, headers=headers, params=None,
                                  timeout=timeout)
    try:
        data: Dict[str, Any] = await resp.json()
    except Exception:  # pylint: disable=broad-except
        # For some reason, `gcloud-rest` seems to have intermittent issues
        # parsing this response. In that case, fall back to returning the
        # raw response body.
        try:
            data = {&#39;response&#39;: await resp.text()}
        except (AttributeError, TypeError):
            data = {&#39;response&#39;: resp.text}

    return data</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.get"><code class="name flex">
<span>async def <span class="ident">get</span></span>(<span>self, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the specified table resource by table ID.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def get(
        self, session: Optional[Session] = None,
        timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Gets the specified table resource by table ID.&#34;&#34;&#34;
    project = await self.project()
    url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
           f&#39;{self.dataset_name}/tables/{self.table_name}&#39;)

    return await self._get_url(url, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.insert"><code class="name flex">
<span>async def <span class="ident">insert</span></span>(<span>self, rows: List[Dict[str, Any]], skip_invalid: bool = False, ignore_unknown: bool = True, session: Optional[aiohttp.client.ClientSession] = None, template_suffix: Optional[str] = None, timeout: int = 60, *, insert_id_fn: Optional[Callable[[Dict[str, Any]], str]] = None) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Streams data into BigQuery</p>
<p>By default, each row is assigned a unique insertId. This can be
customized by supplying an <code>insert_id_fn</code> which takes a row and
returns an insertId.</p>
<p>In cases where at least one row has successfully been inserted and at
least one row has failed to be inserted, the Google API will return a
2xx (successful) response along with an <code>insertErrors</code> key in the
response JSON containing details on the failing rows.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert(
        self, rows: List[Dict[str, Any]], skip_invalid: bool = False,
        ignore_unknown: bool = True, session: Optional[Session] = None,
        template_suffix: Optional[str] = None,
        timeout: int = 60, *,
        insert_id_fn: Optional[Callable[[Dict[str, Any]], str]] = None,
) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;
    Streams data into BigQuery

    By default, each row is assigned a unique insertId. This can be
    customized by supplying an `insert_id_fn` which takes a row and
    returns an insertId.

    In cases where at least one row has successfully been inserted and at
    least one row has failed to be inserted, the Google API will return a
    2xx (successful) response along with an `insertErrors` key in the
    response JSON containing details on the failing rows.
    &#34;&#34;&#34;
    if not rows:
        return {}

    project = await self.project()
    url = (f&#39;{API_ROOT}/projects/{project}/datasets/{self.dataset_name}/&#39;
           f&#39;tables/{self.table_name}/insertAll&#39;)

    body = self._make_insert_body(
        rows, skip_invalid=skip_invalid, ignore_unknown=ignore_unknown,
        template_suffix=template_suffix,
        insert_id_fn=insert_id_fn or self._mk_unique_insert_id)
    return await self._post_json(url, body, session, timeout)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.insert_via_copy"><code class="name flex">
<span>async def <span class="ident">insert_via_copy</span></span>(<span>self, destination_project: str, destination_dataset: str, destination_table: str, session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> <a title="gcloud.aio.bigquery.job.Job" href="job.html#gcloud.aio.bigquery.job.Job">Job</a></span>
</code></dt>
<dd>
<div class="desc"><p>Copy BQ table to another table in BQ</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert_via_copy(
        self, destination_project: str, destination_dataset: str,
        destination_table: str, session: Optional[Session] = None,
        timeout: int = 60) -&gt; Job:
    &#34;&#34;&#34;Copy BQ table to another table in BQ&#34;&#34;&#34;
    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

    body = self._make_copy_body(
        project, destination_project,
        destination_dataset, destination_table)
    response = await self._post_json(url, body, session, timeout)
    return Job(response[&#39;jobReference&#39;][&#39;jobId&#39;], self._project,
               session=self.session.session,  # type: ignore[arg-type]
               token=self.token)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.insert_via_load"><code class="name flex">
<span>async def <span class="ident">insert_via_load</span></span>(<span>self, source_uris: List[str], session: Optional[aiohttp.client.ClientSession] = None, autodetect: bool = False, source_format: <a title="gcloud.aio.bigquery.bigquery.SourceFormat" href="bigquery.html#gcloud.aio.bigquery.bigquery.SourceFormat">SourceFormat</a> = SourceFormat.CSV, write_disposition: <a title="gcloud.aio.bigquery.bigquery.Disposition" href="bigquery.html#gcloud.aio.bigquery.bigquery.Disposition">Disposition</a> = Disposition.WRITE_TRUNCATE, timeout: int = 60, ignore_unknown_values: bool = False, schema_update_options: Optional[List[<a title="gcloud.aio.bigquery.bigquery.SchemaUpdateOption" href="bigquery.html#gcloud.aio.bigquery.bigquery.SchemaUpdateOption">SchemaUpdateOption</a>]] = None) ‑> <a title="gcloud.aio.bigquery.job.Job" href="job.html#gcloud.aio.bigquery.job.Job">Job</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads entities from storage to BigQuery.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert_via_load(
        self, source_uris: List[str], session: Optional[Session] = None,
        autodetect: bool = False,
        source_format: SourceFormat = SourceFormat.CSV,
        write_disposition: Disposition = Disposition.WRITE_TRUNCATE,
        timeout: int = 60,
        ignore_unknown_values: bool = False,
        schema_update_options: Optional[List[SchemaUpdateOption]] = None
) -&gt; Job:
    &#34;&#34;&#34;Loads entities from storage to BigQuery.&#34;&#34;&#34;
    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

    body = self._make_load_body(
        source_uris, project, autodetect, source_format, write_disposition,
        ignore_unknown_values, schema_update_options or []
    )
    response = await self._post_json(url, body, session, timeout)
    return Job(response[&#39;jobReference&#39;][&#39;jobId&#39;], self._project,
               session=self.session.session,  # type: ignore[arg-type]
               token=self.token)</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.insert_via_query"><code class="name flex">
<span>async def <span class="ident">insert_via_query</span></span>(<span>self, query: str, session: Optional[aiohttp.client.ClientSession] = None, write_disposition: <a title="gcloud.aio.bigquery.bigquery.Disposition" href="bigquery.html#gcloud.aio.bigquery.bigquery.Disposition">Disposition</a> = Disposition.WRITE_EMPTY, timeout: int = 60, use_query_cache: bool = True, dry_run: bool = False) ‑> <a title="gcloud.aio.bigquery.job.Job" href="job.html#gcloud.aio.bigquery.job.Job">Job</a></span>
</code></dt>
<dd>
<div class="desc"><p>Create table as a result of the query</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def insert_via_query(
        self, query: str, session: Optional[Session] = None,
        write_disposition: Disposition = Disposition.WRITE_EMPTY,
        timeout: int = 60, use_query_cache: bool = True,
        dry_run: bool = False) -&gt; Job:
    &#34;&#34;&#34;Create table as a result of the query&#34;&#34;&#34;
    warnings.warn(&#39;using Table#insert_via_query is deprecated.&#39;
                  &#39;use Job#insert_via_query instead&#39;, DeprecationWarning)
    project = await self.project()
    url = f&#39;{API_ROOT}/projects/{project}/jobs&#39;

    body = self._make_query_body(query, project, write_disposition,
                                 use_query_cache, dry_run)
    response = await self._post_json(url, body, session, timeout)
    job_id = response[&#39;jobReference&#39;][&#39;jobId&#39;] if not dry_run else None
    return Job(job_id, self._project, token=self.token,
               session=self.session.session)  # type: ignore[arg-type]</code></pre>
</details>
</dd>
<dt id="gcloud.aio.bigquery.Table.patch"><code class="name flex">
<span>async def <span class="ident">patch</span></span>(<span>self, table: Dict[str, Any], session: Optional[aiohttp.client.ClientSession] = None, timeout: int = 60) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Patch an existing table specified by tableId from the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def patch(self, table: Dict[str, Any],
                session: Optional[Session] = None,
                timeout: int = 60) -&gt; Dict[str, Any]:
    &#34;&#34;&#34;Patch an existing table specified by tableId from the dataset.&#34;&#34;&#34;
    project = await self.project()
    url = (f&#39;{API_ROOT}/projects/{project}/datasets/&#39;
           f&#39;{self.dataset_name}/tables/{self.table_name}&#39;)

    table[&#39;tableReference&#39;] = {
        &#39;projectId&#39;: project,
        &#39;datasetId&#39;: self.dataset_name,
        &#39;tableId&#39;: self.table_name
    }
    table_data = json.dumps(table).encode(&#39;utf-8&#39;)

    headers = await self.headers()

    s = AioSession(session) if session else self.session
    # TODO: the type issue will be fixed in auth-4.0.2
    resp = await s.patch(url, data=table_data,  # type: ignore[arg-type]
                         headers=headers, timeout=timeout)
    data: Dict[str, Any] = await resp.json()
    return data</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gcloud.aio" href="../index.html">gcloud.aio</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="gcloud.aio.bigquery.bigquery" href="bigquery.html">gcloud.aio.bigquery.bigquery</a></code></li>
<li><code><a title="gcloud.aio.bigquery.dataset" href="dataset.html">gcloud.aio.bigquery.dataset</a></code></li>
<li><code><a title="gcloud.aio.bigquery.job" href="job.html">gcloud.aio.bigquery.job</a></code></li>
<li><code><a title="gcloud.aio.bigquery.table" href="table.html">gcloud.aio.bigquery.table</a></code></li>
<li><code><a title="gcloud.aio.bigquery.utils" href="utils.html">gcloud.aio.bigquery.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="gcloud.aio.bigquery.query_response_to_dict" href="#gcloud.aio.bigquery.query_response_to_dict">query_response_to_dict</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="gcloud.aio.bigquery.Dataset" href="#gcloud.aio.bigquery.Dataset">Dataset</a></code></h4>
<ul class="">
<li><code><a title="gcloud.aio.bigquery.Dataset.get" href="#gcloud.aio.bigquery.Dataset.get">get</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Dataset.insert" href="#gcloud.aio.bigquery.Dataset.insert">insert</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Dataset.list_datasets" href="#gcloud.aio.bigquery.Dataset.list_datasets">list_datasets</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Dataset.list_tables" href="#gcloud.aio.bigquery.Dataset.list_tables">list_tables</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="gcloud.aio.bigquery.Disposition" href="#gcloud.aio.bigquery.Disposition">Disposition</a></code></h4>
<ul class="">
<li><code><a title="gcloud.aio.bigquery.Disposition.WRITE_APPEND" href="#gcloud.aio.bigquery.Disposition.WRITE_APPEND">WRITE_APPEND</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Disposition.WRITE_EMPTY" href="#gcloud.aio.bigquery.Disposition.WRITE_EMPTY">WRITE_EMPTY</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Disposition.WRITE_TRUNCATE" href="#gcloud.aio.bigquery.Disposition.WRITE_TRUNCATE">WRITE_TRUNCATE</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="gcloud.aio.bigquery.Job" href="#gcloud.aio.bigquery.Job">Job</a></code></h4>
<ul class="two-column">
<li><code><a title="gcloud.aio.bigquery.Job.cancel" href="#gcloud.aio.bigquery.Job.cancel">cancel</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Job.get_job" href="#gcloud.aio.bigquery.Job.get_job">get_job</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Job.get_query_results" href="#gcloud.aio.bigquery.Job.get_query_results">get_query_results</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Job.insert" href="#gcloud.aio.bigquery.Job.insert">insert</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Job.insert_via_query" href="#gcloud.aio.bigquery.Job.insert_via_query">insert_via_query</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Job.query" href="#gcloud.aio.bigquery.Job.query">query</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Job.result" href="#gcloud.aio.bigquery.Job.result">result</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="gcloud.aio.bigquery.SchemaUpdateOption" href="#gcloud.aio.bigquery.SchemaUpdateOption">SchemaUpdateOption</a></code></h4>
<ul class="">
<li><code><a title="gcloud.aio.bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION" href="#gcloud.aio.bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION">ALLOW_FIELD_ADDITION</a></code></li>
<li><code><a title="gcloud.aio.bigquery.SchemaUpdateOption.ALLOW_FIELD_RELAXATION" href="#gcloud.aio.bigquery.SchemaUpdateOption.ALLOW_FIELD_RELAXATION">ALLOW_FIELD_RELAXATION</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="gcloud.aio.bigquery.SourceFormat" href="#gcloud.aio.bigquery.SourceFormat">SourceFormat</a></code></h4>
<ul class="">
<li><code><a title="gcloud.aio.bigquery.SourceFormat.AVRO" href="#gcloud.aio.bigquery.SourceFormat.AVRO">AVRO</a></code></li>
<li><code><a title="gcloud.aio.bigquery.SourceFormat.CSV" href="#gcloud.aio.bigquery.SourceFormat.CSV">CSV</a></code></li>
<li><code><a title="gcloud.aio.bigquery.SourceFormat.DATASTORE_BACKUP" href="#gcloud.aio.bigquery.SourceFormat.DATASTORE_BACKUP">DATASTORE_BACKUP</a></code></li>
<li><code><a title="gcloud.aio.bigquery.SourceFormat.NEWLINE_DELIMITED_JSON" href="#gcloud.aio.bigquery.SourceFormat.NEWLINE_DELIMITED_JSON">NEWLINE_DELIMITED_JSON</a></code></li>
<li><code><a title="gcloud.aio.bigquery.SourceFormat.ORC" href="#gcloud.aio.bigquery.SourceFormat.ORC">ORC</a></code></li>
<li><code><a title="gcloud.aio.bigquery.SourceFormat.PARQUET" href="#gcloud.aio.bigquery.SourceFormat.PARQUET">PARQUET</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="gcloud.aio.bigquery.Table" href="#gcloud.aio.bigquery.Table">Table</a></code></h4>
<ul class="two-column">
<li><code><a title="gcloud.aio.bigquery.Table.create" href="#gcloud.aio.bigquery.Table.create">create</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.delete" href="#gcloud.aio.bigquery.Table.delete">delete</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.get" href="#gcloud.aio.bigquery.Table.get">get</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.insert" href="#gcloud.aio.bigquery.Table.insert">insert</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.insert_via_copy" href="#gcloud.aio.bigquery.Table.insert_via_copy">insert_via_copy</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.insert_via_load" href="#gcloud.aio.bigquery.Table.insert_via_load">insert_via_load</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.insert_via_query" href="#gcloud.aio.bigquery.Table.insert_via_query">insert_via_query</a></code></li>
<li><code><a title="gcloud.aio.bigquery.Table.patch" href="#gcloud.aio.bigquery.Table.patch">patch</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>